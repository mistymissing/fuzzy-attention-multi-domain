"""
Domain Adapter åŸºç±» - UniMatch-Clipé¡¹ç›®æ ¸å¿ƒæ¶æ„ç»„ä»¶

åŠŸèƒ½ï¼š
1. ç»Ÿä¸€å››ä¸ªé¢†åŸŸçš„æ¥å£æŠ½è±¡ (Vision/NLP/Security/Medical)
2. è·¨åŸŸç‰¹å¾æ ‡å‡†åŒ–å’Œè½¬æ¢
3. é¢†åŸŸç‰¹å®šçš„æ•°æ®é¢„å¤„ç†
4. ç½®ä¿¡åº¦è®¡ç®—å’Œå›°éš¾æ ·æœ¬è¯†åˆ«çš„ç»Ÿä¸€æ¥å£
5. å¯æ’æ‹”çš„é¢†åŸŸé€‚é…å™¨æ¶æ„

è®¾è®¡ç†å¿µï¼š
- æ¯ä¸ªé¢†åŸŸæœ‰ç‹¬ç‰¹çš„æ•°æ®æ ¼å¼å’Œæ¨¡å‹æ¶æ„
- é€šè¿‡ç»Ÿä¸€æ¥å£å®ç°è·¨åŸŸåä½œ
- æ”¯æŒåŠ¨æ€åˆ‡æ¢å’Œç»„åˆä¸åŒé¢†åŸŸ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
import json
import time
from pathlib import Path


class DomainType(Enum):
    """é¢†åŸŸç±»å‹æšä¸¾"""
    VISION = "vision"
    NLP = "nlp"
    SECURITY = "security"
    MEDICAL = "medical"


class AdapterMode(Enum):
    """é€‚é…å™¨æ¨¡å¼æšä¸¾"""
    TRAINING = "training"  # è®­ç»ƒæ¨¡å¼
    INFERENCE = "inference"  # æ¨ç†æ¨¡å¼
    EVALUATION = "evaluation"  # è¯„ä¼°æ¨¡å¼


@dataclass
class AdapterInput:
    """é€‚é…å™¨è¾“å…¥æ•°æ®ç»“æ„"""
    raw_data: Any  # åŸå§‹è¾“å…¥æ•°æ® (å›¾åƒ/æ–‡æœ¬/ä¿¡å·ç­‰)
    labels: Optional[Any] = None  # æ ‡ç­¾ (è®­ç»ƒæ—¶ä½¿ç”¨)
    metadata: Dict[str, Any] = field(default_factory=dict)  # å…ƒæ•°æ®
    batch_size: Optional[int] = None  # æ‰¹æ¬¡å¤§å°
    device: Optional[torch.device] = None  # è®¾å¤‡ä¿¡æ¯


@dataclass
class AdapterOutput:
    """é€‚é…å™¨è¾“å‡ºæ•°æ®ç»“æ„"""
    # æ ¸å¿ƒè¾“å‡º
    embeddings: torch.Tensor  # æ ‡å‡†åŒ–ç‰¹å¾åµŒå…¥ [B, D]
    logits: torch.Tensor  # é¢„æµ‹logits [B, num_classes]
    confidence_scores: torch.Tensor  # ç½®ä¿¡åº¦åˆ†æ•° [B]

    # ä¸­é—´è¡¨ç¤º
    raw_features: Optional[torch.Tensor] = None  # åŸå§‹ç‰¹å¾
    attention_weights: Optional[torch.Tensor] = None  # æ³¨æ„åŠ›æƒé‡

    # å…ƒä¿¡æ¯
    processing_time: float = 0.0  # å¤„ç†æ—¶é—´
    metadata: Dict[str, Any] = field(default_factory=dict)  # è¾“å‡ºå…ƒæ•°æ®

    # å›°éš¾æ ·æœ¬ç›¸å…³
    is_hard_sample: Optional[torch.Tensor] = None  # æ˜¯å¦å›°éš¾æ ·æœ¬ [B]
    difficulty_scores: Optional[torch.Tensor] = None  # å›°éš¾åº¦åˆ†æ•° [B]


class BaseDomainAdapter(ABC, nn.Module):
    """
    Domain Adapter åŸºç±»

    æ‰€æœ‰é¢†åŸŸé€‚é…å™¨çš„æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰ç»Ÿä¸€æ¥å£
    """

    def __init__(self,
                 domain_type: DomainType,
                 input_dim: int,
                 hidden_dim: int = 512,
                 output_dim: int = 256,
                 num_classes: Optional[int] = None,
                 dropout_rate: float = 0.1,
                 device: Optional[torch.device] = None):
        """
        Args:
            domain_type: é¢†åŸŸç±»å‹
            input_dim: è¾“å…¥ç‰¹å¾ç»´åº¦
            hidden_dim: éšè—å±‚ç»´åº¦
            output_dim: ç»Ÿä¸€è¾“å‡ºç»´åº¦ (è·¨åŸŸå¯¹é½çš„ç›®æ ‡ç»´åº¦)
            num_classes: åˆ†ç±»ç±»åˆ«æ•° (å¦‚æœæ˜¯åˆ†ç±»ä»»åŠ¡)
            dropout_rate: Dropoutç‡
            device: è®¡ç®—è®¾å¤‡
        """
        super().__init__()

        self.domain_type = domain_type
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_classes = num_classes
        self.dropout_rate = dropout_rate
        self.device = device or torch.device('cpu')

        # é€‚é…å™¨çŠ¶æ€
        self.mode = AdapterMode.TRAINING
        self.is_initialized = False

        # ç»Ÿè®¡ä¿¡æ¯
        self.processing_stats = {
            'total_samples': 0,
            'hard_samples': 0,
            'avg_confidence': 0.0,
            'avg_processing_time': 0.0
        }

        # æ—¥å¿—
        self.logger = logging.getLogger(f"{domain_type.value}Adapter")

        # æ ¸å¿ƒç»„ä»¶ (å­ç±»éœ€è¦å®ç°)
        self.feature_extractor = None  # ç‰¹å¾æå–å™¨
        self.embedding_projector = None  # åµŒå…¥æŠ•å½±å™¨
        self.classifier = None  # åˆ†ç±»å™¨ (å¯é€‰)
        self.confidence_estimator = None  # ç½®ä¿¡åº¦ä¼°è®¡å™¨

        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self._init_core_components()

        # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.to(self.device)

    def _init_core_components(self):
        """åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶ - é€šç”¨å®ç°"""

        # æ ‡å‡†åµŒå…¥æŠ•å½±å™¨ (è¾“å…¥ç»´åº¦ -> ç»Ÿä¸€è¾“å‡ºç»´åº¦)
        self.embedding_projector = nn.Sequential(
            nn.Linear(self.input_dim, self.hidden_dim),
            nn.LayerNorm(self.hidden_dim),
            nn.ReLU(),
            nn.Dropout(self.dropout_rate),
            nn.Linear(self.hidden_dim, self.output_dim),
            nn.LayerNorm(self.output_dim)
        )

        # åˆ†ç±»å™¨ (å¦‚æœæŒ‡å®šäº†ç±»åˆ«æ•°)
        if self.num_classes:
            self.classifier = nn.Sequential(
                nn.Linear(self.output_dim, self.hidden_dim // 2),
                nn.ReLU(),
                nn.Dropout(self.dropout_rate),
                nn.Linear(self.hidden_dim // 2, self.num_classes)
            )

        # ç½®ä¿¡åº¦ä¼°è®¡å™¨ (åŸºäºç‰¹å¾å’Œé¢„æµ‹çš„ç½®ä¿¡åº¦)
        confidence_input_dim = self.output_dim
        if self.num_classes:
            confidence_input_dim += self.num_classes  # æ‹¼æ¥logits

        self.confidence_estimator = nn.Sequential(
            nn.Linear(confidence_input_dim, self.hidden_dim // 4),
            nn.ReLU(),
            nn.Dropout(self.dropout_rate / 2),
            nn.Linear(self.hidden_dim // 4, 1),
            nn.Sigmoid()  # è¾“å‡º[0,1]ç½®ä¿¡åº¦
        )

    @abstractmethod
    def extract_features(self, inputs: AdapterInput) -> torch.Tensor:
        """
        æå–é¢†åŸŸç‰¹å®šç‰¹å¾ - å­ç±»å¿…é¡»å®ç°

        Args:
            inputs: é€‚é…å™¨è¾“å…¥

        Returns:
            åŸå§‹ç‰¹å¾å¼ é‡ [B, input_dim]
        """
        pass

    @abstractmethod
    def preprocess_data(self, raw_data: Any) -> torch.Tensor:
        """
        é¢†åŸŸç‰¹å®šçš„æ•°æ®é¢„å¤„ç† - å­ç±»å¿…é¡»å®ç°

        Args:
            raw_data: åŸå§‹æ•°æ® (å›¾åƒ/æ–‡æœ¬/ä¿¡å·ç­‰)

        Returns:
            é¢„å¤„ç†åçš„å¼ é‡
        """
        pass

    def forward(self, inputs: AdapterInput) -> AdapterOutput:
        """
        é€‚é…å™¨å‰å‘ä¼ æ’­ - ç»Ÿä¸€å¤„ç†æµç¨‹

        Args:
            inputs: é€‚é…å™¨è¾“å…¥

        Returns:
            é€‚é…å™¨è¾“å‡º
        """
        start_time = time.time()

        # 1. æ•°æ®é¢„å¤„ç†
        preprocessed_data = self.preprocess_data(inputs.raw_data)

        # 2. ç‰¹å¾æå– (é¢†åŸŸç‰¹å®š)
        raw_features = self.extract_features(AdapterInput(
            raw_data=preprocessed_data,
            labels=inputs.labels,
            metadata=inputs.metadata,
            device=self.device
        ))

        # 3. åµŒå…¥æŠ•å½± (æ ‡å‡†åŒ–åˆ°ç»Ÿä¸€ç»´åº¦)
        embeddings = self.embedding_projector(raw_features)

        # 4. åˆ†ç±»é¢„æµ‹ (å¦‚æœæœ‰åˆ†ç±»å™¨)
        logits = None
        if self.classifier is not None:
            logits = self.classifier(embeddings)
        else:
            # å¦‚æœæ²¡æœ‰åˆ†ç±»å™¨ï¼Œè¿”å›é›¶å‘é‡
            batch_size = embeddings.size(0)
            logits = torch.zeros(batch_size, self.num_classes or 1, device=self.device)

        # 5. ç½®ä¿¡åº¦ä¼°è®¡
        confidence_scores = self._compute_confidence(embeddings, logits)

        # 6. å›°éš¾æ ·æœ¬è¯†åˆ«
        is_hard_sample, difficulty_scores = self._identify_hard_samples(confidence_scores)

        # 7. æ„å»ºè¾“å‡º
        processing_time = time.time() - start_time

        output = AdapterOutput(
            embeddings=embeddings,
            logits=logits,
            confidence_scores=confidence_scores,
            raw_features=raw_features,
            processing_time=processing_time,
            is_hard_sample=is_hard_sample,
            difficulty_scores=difficulty_scores,
            metadata={
                'domain': self.domain_type.value,
                'batch_size': embeddings.size(0),
                'feature_dim': embeddings.size(1)
            }
        )

        # 8. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self._update_stats(output)

        return output

    def _compute_confidence(self, embeddings: torch.Tensor,
                            logits: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°"""

        # å‡†å¤‡ç½®ä¿¡åº¦ä¼°è®¡å™¨çš„è¾“å…¥
        if logits is not None and logits.numel() > 0:
            # æ‹¼æ¥åµŒå…¥å’Œlogits
            confidence_input = torch.cat([embeddings, logits], dim=-1)
        else:
            confidence_input = embeddings

        # ä½¿ç”¨ç½®ä¿¡åº¦ä¼°è®¡å™¨
        confidence_scores = self.confidence_estimator(confidence_input).squeeze(-1)

        return confidence_scores

    def _identify_hard_samples(self, confidence_scores: torch.Tensor,
                               threshold: Optional[float] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """è¯†åˆ«å›°éš¾æ ·æœ¬"""

        if threshold is None:
            # ä½¿ç”¨é¢†åŸŸç‰¹å®šçš„é»˜è®¤é˜ˆå€¼
            domain_thresholds = {
                DomainType.VISION: 0.7,
                DomainType.NLP: 0.6,
                DomainType.SECURITY: 0.8,
                DomainType.MEDICAL: 0.75
            }
            threshold = domain_thresholds.get(self.domain_type, 0.7)

        # å›°éš¾æ ·æœ¬æ ‡è¯†
        is_hard_sample = confidence_scores < threshold

        # å›°éš¾åº¦åˆ†æ•° (ç½®ä¿¡åº¦è¶Šä½ï¼Œå›°éš¾åº¦è¶Šé«˜)
        difficulty_scores = 1.0 - confidence_scores

        return is_hard_sample, difficulty_scores

    def _update_stats(self, output: AdapterOutput):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        batch_size = output.embeddings.size(0)
        hard_count = output.is_hard_sample.sum().item() if output.is_hard_sample is not None else 0
        avg_confidence = output.confidence_scores.mean().item()

        # æ›´æ–°ç´¯ç§¯ç»Ÿè®¡
        total_samples = self.processing_stats['total_samples']
        self.processing_stats['total_samples'] += batch_size
        self.processing_stats['hard_samples'] += hard_count

        # æ›´æ–°å¹³å‡å€¼
        new_total = total_samples + batch_size
        self.processing_stats['avg_confidence'] = (
                (self.processing_stats['avg_confidence'] * total_samples + avg_confidence * batch_size) / new_total
        )
        self.processing_stats['avg_processing_time'] = (
                (self.processing_stats[
                     'avg_processing_time'] * total_samples + output.processing_time * batch_size) / new_total
        )

    def set_mode(self, mode: AdapterMode):
        """è®¾ç½®é€‚é…å™¨æ¨¡å¼"""
        self.mode = mode
        if mode == AdapterMode.TRAINING:
            self.train()
        else:
            self.eval()

        self.logger.debug(f"Adapter mode set to: {mode.value}")

    def get_embedding_dim(self) -> int:
        """è·å–åµŒå…¥ç»´åº¦"""
        return self.output_dim

    def get_domain_type(self) -> DomainType:
        """è·å–é¢†åŸŸç±»å‹"""
        return self.domain_type

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–é€‚é…å™¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.processing_stats.copy()

        # è®¡ç®—é¢å¤–æŒ‡æ ‡
        if stats['total_samples'] > 0:
            stats['hard_sample_ratio'] = stats['hard_samples'] / stats['total_samples']
        else:
            stats['hard_sample_ratio'] = 0.0

        stats['domain'] = self.domain_type.value
        stats['mode'] = self.mode.value

        return stats

    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.processing_stats = {
            'total_samples': 0,
            'hard_samples': 0,
            'avg_confidence': 0.0,
            'avg_processing_time': 0.0
        }

    def save_adapter(self, save_path: Union[str, Path]):
        """ä¿å­˜é€‚é…å™¨çŠ¶æ€"""
        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)

        state = {
            'state_dict': self.state_dict(),
            'config': {
                'domain_type': self.domain_type.value,
                'input_dim': self.input_dim,
                'hidden_dim': self.hidden_dim,
                'output_dim': self.output_dim,
                'num_classes': self.num_classes,
                'dropout_rate': self.dropout_rate
            },
            'statistics': self.get_statistics()
        }

        torch.save(state, save_path)
        self.logger.info(f"Adapter saved to {save_path}")

    def load_adapter(self, load_path: Union[str, Path]):
        """åŠ è½½é€‚é…å™¨çŠ¶æ€"""
        load_path = Path(load_path)

        if not load_path.exists():
            raise FileNotFoundError(f"Adapter file not found: {load_path}")

        state = torch.load(load_path, map_location=self.device)

        # éªŒè¯é…ç½®å…¼å®¹æ€§
        config = state['config']
        if config['domain_type'] != self.domain_type.value:
            raise ValueError(f"Domain type mismatch: {config['domain_type']} vs {self.domain_type.value}")

        # åŠ è½½æƒé‡
        self.load_state_dict(state['state_dict'])

        # åŠ è½½ç»Ÿè®¡ä¿¡æ¯
        if 'statistics' in state:
            self.processing_stats.update(state['statistics'])

        self.logger.info(f"Adapter loaded from {load_path}")


class AdapterRegistry:
    """é€‚é…å™¨æ³¨å†Œè¡¨ - ç®¡ç†æ‰€æœ‰é¢†åŸŸé€‚é…å™¨"""

    def __init__(self):
        self.adapters = {}  # domain_type -> adapter instance
        self.adapter_classes = {}  # domain_type -> adapter class
        self.logger = logging.getLogger("AdapterRegistry")

    def register_adapter_class(self, domain_type: DomainType, adapter_class):
        """æ³¨å†Œé€‚é…å™¨ç±»"""
        self.adapter_classes[domain_type] = adapter_class
        self.logger.info(f"Registered adapter class for {domain_type.value}")

    def create_adapter(self, domain_type: DomainType, **kwargs) -> BaseDomainAdapter:
        """åˆ›å»ºé€‚é…å™¨å®ä¾‹"""
        if domain_type not in self.adapter_classes:
            raise ValueError(f"No adapter class registered for {domain_type.value}")

        adapter_class = self.adapter_classes[domain_type]
        adapter = adapter_class(domain_type=domain_type, **kwargs)

        self.adapters[domain_type] = adapter
        self.logger.info(f"Created adapter instance for {domain_type.value}")

        return adapter

    def get_adapter(self, domain_type: DomainType) -> Optional[BaseDomainAdapter]:
        """è·å–é€‚é…å™¨å®ä¾‹"""
        return self.adapters.get(domain_type)

    def get_all_adapters(self) -> Dict[DomainType, BaseDomainAdapter]:
        """è·å–æ‰€æœ‰é€‚é…å™¨"""
        return self.adapters.copy()

    def set_mode_all(self, mode: AdapterMode):
        """è®¾ç½®æ‰€æœ‰é€‚é…å™¨çš„æ¨¡å¼"""
        for adapter in self.adapters.values():
            adapter.set_mode(mode)

    def get_unified_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰é€‚é…å™¨çš„ç»Ÿä¸€ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}

        for domain_type, adapter in self.adapters.items():
            stats[domain_type.value] = adapter.get_statistics()

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_samples = sum(s['total_samples'] for s in stats.values())
        total_hard_samples = sum(s['hard_samples'] for s in stats.values())

        stats['overall'] = {
            'total_samples': total_samples,
            'total_hard_samples': total_hard_samples,
            'overall_hard_ratio': total_hard_samples / max(total_samples, 1),
            'active_domains': len(self.adapters)
        }

        return stats


# =====================================================
# æµ‹è¯•å’Œç¤ºä¾‹
# =====================================================

class TestDomainAdapter(BaseDomainAdapter):
    """æµ‹è¯•ç”¨çš„ç®€å•é€‚é…å™¨å®ç°"""

    def extract_features(self, inputs: AdapterInput) -> torch.Tensor:
        """ç®€å•çš„ç‰¹å¾æå– - ç›´æ¥è¿”å›é¢„å¤„ç†åçš„æ•°æ®"""
        if isinstance(inputs.raw_data, torch.Tensor):
            return inputs.raw_data
        else:
            # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå¼ é‡
            return torch.tensor(inputs.raw_data, dtype=torch.float32, device=self.device)

    def preprocess_data(self, raw_data: Any) -> torch.Tensor:
        """ç®€å•çš„æ•°æ®é¢„å¤„ç†"""
        if isinstance(raw_data, torch.Tensor):
            return raw_data.to(self.device)
        elif isinstance(raw_data, np.ndarray):
            return torch.from_numpy(raw_data).float().to(self.device)
        elif isinstance(raw_data, list):
            return torch.tensor(raw_data, dtype=torch.float32, device=self.device)
        else:
            raise ValueError(f"Unsupported raw_data type: {type(raw_data)}")


def test_base_adapter():
    """æµ‹è¯•åŸºç¡€é€‚é…å™¨åŠŸèƒ½"""

    print("ğŸ§ª æµ‹è¯•Domain AdapteråŸºç±»...")

    # åˆ›å»ºæµ‹è¯•é€‚é…å™¨
    adapter = TestDomainAdapter(
        domain_type=DomainType.VISION,
        input_dim=512,
        hidden_dim=256,
        output_dim=128,
        num_classes=10,
        dropout_rate=0.1
    )

    print(f"âœ… åˆ›å»ºé€‚é…å™¨: {adapter.get_domain_type().value}")
    print(f"ğŸ“ åµŒå…¥ç»´åº¦: {adapter.get_embedding_dim()}")

    # æµ‹è¯•æ•°æ®
    batch_size = 4
    test_data = torch.randn(batch_size, 512)
    test_labels = torch.randint(0, 10, (batch_size,))

    # åˆ›å»ºè¾“å…¥
    inputs = AdapterInput(
        raw_data=test_data,
        labels=test_labels,
        metadata={'test': True},
        batch_size=batch_size
    )

    # å‰å‘ä¼ æ’­
    adapter.set_mode(AdapterMode.INFERENCE)
    outputs = adapter(inputs)

    print(f"\nğŸ“Š é€‚é…å™¨è¾“å‡º:")
    print(f"åµŒå…¥å½¢çŠ¶: {outputs.embeddings.shape}")
    print(f"Logitså½¢çŠ¶: {outputs.logits.shape}")
    print(f"ç½®ä¿¡åº¦: {outputs.confidence_scores}")
    print(f"å›°éš¾æ ·æœ¬: {outputs.is_hard_sample}")
    print(f"å¤„ç†æ—¶é—´: {outputs.processing_time:.4f}ç§’")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = adapter.get_statistics()
    print(f"\nğŸ“ˆ é€‚é…å™¨ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"{key}: {value}")

    return True


def test_adapter_registry():
    """æµ‹è¯•é€‚é…å™¨æ³¨å†Œè¡¨"""

    print("\nğŸ›ï¸ æµ‹è¯•é€‚é…å™¨æ³¨å†Œè¡¨...")

    # åˆ›å»ºæ³¨å†Œè¡¨
    registry = AdapterRegistry()

    # æ³¨å†Œé€‚é…å™¨ç±»
    registry.register_adapter_class(DomainType.VISION, TestDomainAdapter)
    registry.register_adapter_class(DomainType.NLP, TestDomainAdapter)

    # åˆ›å»ºé€‚é…å™¨å®ä¾‹
    vision_adapter = registry.create_adapter(
        DomainType.VISION,
        input_dim=512,
        output_dim=128,
        num_classes=10
    )

    nlp_adapter = registry.create_adapter(
        DomainType.NLP,
        input_dim=768,
        output_dim=128,
        num_classes=5
    )

    print(f"âœ… åˆ›å»ºäº† {len(registry.get_all_adapters())} ä¸ªé€‚é…å™¨")

    # æµ‹è¯•æ¨¡å¼åˆ‡æ¢
    registry.set_mode_all(AdapterMode.TRAINING)
    print("ğŸ“š æ‰€æœ‰é€‚é…å™¨è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼")

    # ç»Ÿä¸€ç»Ÿè®¡
    unified_stats = registry.get_unified_statistics()
    print(f"\nğŸ“Š ç»Ÿä¸€ç»Ÿè®¡ä¿¡æ¯:")
    for domain, stats in unified_stats.items():
        if domain != 'overall':
            print(f"{domain}: {stats['total_samples']} æ ·æœ¬")

    print(f"æ€»ä½“: {unified_stats['overall']}")

    return True


def demonstrate_adapter_workflow():
    """æ¼”ç¤ºé€‚é…å™¨çš„å®Œæ•´å·¥ä½œæµç¨‹"""

    print("\nğŸ”„ æ¼”ç¤ºé€‚é…å™¨å·¥ä½œæµç¨‹...")

    # 1. åˆ›å»ºä¸åŒé¢†åŸŸçš„é€‚é…å™¨
    domains_config = {
        DomainType.VISION: {'input_dim': 512, 'num_classes': 10},
        DomainType.NLP: {'input_dim': 768, 'num_classes': 5},
        DomainType.SECURITY: {'input_dim': 256, 'num_classes': 2},
        DomainType.MEDICAL: {'input_dim': 384, 'num_classes': 4}
    }

    adapters = {}
    for domain, config in domains_config.items():
        adapter = TestDomainAdapter(
            domain_type=domain,
            output_dim=128,  # ç»Ÿä¸€è¾“å‡ºç»´åº¦
            **config
        )
        adapters[domain] = adapter

    print(f"âœ… åˆ›å»ºäº† {len(adapters)} ä¸ªé¢†åŸŸé€‚é…å™¨")

    # 2. æ¨¡æ‹Ÿå„é¢†åŸŸçš„æ•°æ®å¤„ç†
    results = {}

    for domain, adapter in adapters.items():
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        input_dim = domains_config[domain]['input_dim']
        test_data = torch.randn(3, input_dim)  # 3ä¸ªæ ·æœ¬

        inputs = AdapterInput(
            raw_data=test_data,
            metadata={'domain': domain.value}
        )

        # å¤„ç†æ•°æ®
        outputs = adapter(inputs)
        results[domain] = outputs

        print(f"ğŸ”§ {domain.value}: å¤„ç†äº†3ä¸ªæ ·æœ¬ï¼Œå›°éš¾æ ·æœ¬: {outputs.is_hard_sample.sum().item()}ä¸ª")

    # 3. éªŒè¯è·¨åŸŸä¸€è‡´æ€§
    print(f"\nğŸŒ è·¨åŸŸä¸€è‡´æ€§æ£€æŸ¥:")
    embedding_dims = [result.embeddings.shape[1] for result in results.values()]

    if len(set(embedding_dims)) == 1:
        print(f"âœ… æ‰€æœ‰é¢†åŸŸè¾“å‡ºç»´åº¦ä¸€è‡´: {embedding_dims[0]}")
    else:
        print(f"âŒ è¾“å‡ºç»´åº¦ä¸ä¸€è‡´: {embedding_dims}")

    # 4. è®¡ç®—è·¨åŸŸç›¸ä¼¼åº¦ (ç®€å•ç¤ºä¾‹)
    print(f"\nğŸ” è·¨åŸŸç‰¹å¾ç›¸ä¼¼åº¦åˆ†æ:")
    domain_embeddings = {}

    for domain, result in results.items():
        # å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„åµŒå…¥
        domain_embeddings[domain] = result.embeddings[0]

    # è®¡ç®—å„é¢†åŸŸé—´çš„ç›¸ä¼¼åº¦
    domain_list = list(domain_embeddings.keys())
    for i, domain1 in enumerate(domain_list):
        for j, domain2 in enumerate(domain_list[i + 1:], i + 1):
            emb1 = domain_embeddings[domain1]
            emb2 = domain_embeddings[domain2]

            similarity = F.cosine_similarity(emb1, emb2, dim=0).item()
            print(f"{domain1.value} â†” {domain2.value}: ç›¸ä¼¼åº¦ {similarity:.4f}")

    return True


if __name__ == "__main__":
    print("ğŸš€ Domain Adapter åŸºç±»æµ‹è¯•å¯åŠ¨")
    print("=" * 50)

    # åŸºç¡€åŠŸèƒ½æµ‹è¯•
    basic_success = test_base_adapter()

    if basic_success:
        # æ³¨å†Œè¡¨æµ‹è¯•
        registry_success = test_adapter_registry()

        # å·¥ä½œæµç¨‹æ¼”ç¤º
        workflow_success = demonstrate_adapter_workflow()

        if all([registry_success, workflow_success]):
            print("\nğŸ‰ Domain Adapter åŸºç±»å®Œå…¨å°±ç»ª!")
            print("âœ… ç»Ÿä¸€æ¥å£è®¾è®¡éªŒè¯é€šè¿‡")
            print("âœ… è·¨åŸŸç‰¹å¾æ ‡å‡†åŒ–å·¥ä½œæ­£å¸¸")
            print("âœ… é€‚é…å™¨æ³¨å†Œå’Œç®¡ç†ç³»ç»Ÿæ­£å¸¸")
            print("\nğŸš€ å¯ä»¥å¼€å§‹å…·ä½“é¢†åŸŸé€‚é…å™¨çš„å®ç°!")
            print("ğŸ“‹ ä¸‹ä¸€æ­¥: Vision å’Œ NLP é€‚é…å™¨å®ç°")
        else:
            print("\nâš ï¸ éƒ¨åˆ†é«˜çº§åŠŸèƒ½éœ€è¦è°ƒè¯•")
    else:
        print("\nâŒ éœ€è¦è°ƒè¯•åŸºç¡€é€‚é…å™¨")