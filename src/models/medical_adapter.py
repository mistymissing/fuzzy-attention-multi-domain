"""
Medical é€‚é…å™¨ - UniMatch-Clipé¡¹ç›®åŒ»ç–—é¢†åŸŸå®ç°

åŠŸèƒ½ï¼š
1. åŒ»å­¦å½±åƒåˆ†æ (X-ray, CT, MRI)
2. ç–¾ç—…è¯Šæ–­è¾…åŠ©
3. ç½•è§ç–¾ç—…è¯†åˆ«
4. ç—…ç†ç‰¹å¾æå–
5. å¤šæ¨¡æ€åŒ»ç–—æ•°æ®èåˆ

æ”¯æŒçš„æ•°æ®é›†ï¼š
- ChestX-ray14 (èƒ¸éƒ¨Xå…‰)
- MIMIC-CXR (åŒ»ç–—å½±åƒ)
- NIH Chest X-rays (è‚ºéƒ¨ç–¾ç—…)
- ISIC (çš®è‚¤ç—…å˜)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple, Any, Union
import logging
from dataclasses import dataclass
from torchvision import transforms
import warnings


# å‡è®¾base_adapteråœ¨åŒä¸€ç›®å½•
class DomainType:
    VISION = "vision"
    NLP = "nlp"
    SECURITY = "security"
    MEDICAL = "medical"


class AdapterMode:
    TRAINING = "training"
    INFERENCE = "inference"
    HARD_SAMPLE_MINING = "hard_sample_mining"


@dataclass
class AdapterInput:
    raw_data: Any
    labels: Optional[torch.Tensor] = None
    metadata: Optional[Dict] = None


@dataclass
class AdapterOutput:
    embeddings: torch.Tensor
    confidence_scores: torch.Tensor
    is_hard_sample: torch.Tensor
    logits: Optional[torch.Tensor] = None  # å¯é€‰å‚æ•°æ”¾æœ€å
    metadata: Optional[Dict] = None  # å¯é€‰å‚æ•°æ”¾æœ€å


# å¦‚æœèƒ½å¯¼å…¥åŸºç±»ï¼Œä½¿ç”¨ä¸‹é¢çš„å¯¼å…¥
# from base_adapter import BaseDomainAdapter, DomainType, AdapterInput, AdapterOutput, AdapterMode

class MedicalModalityType:
    """åŒ»ç–—æ•°æ®æ¨¡æ€ç±»å‹"""
    XRAY = "xray"
    CT = "ct"
    MRI = "mri"
    PATHOLOGY = "pathology"
    CLINICAL = "clinical"  # ä¸´åºŠæ•°æ®
    MULTIMODAL = "multimodal"  # å¤šæ¨¡æ€


@dataclass
class MedicalFeatures:
    """åŒ»ç–—ç‰¹å¾æ•°æ®ç»“æ„"""
    image_features: Optional[torch.Tensor] = None  # å½±åƒç‰¹å¾
    clinical_features: Optional[torch.Tensor] = None  # ä¸´åºŠç‰¹å¾
    lab_features: Optional[torch.Tensor] = None  # å®éªŒå®¤æ£€æŸ¥ç‰¹å¾
    demographic_features: Optional[torch.Tensor] = None  # äººå£ç»Ÿè®¡å­¦ç‰¹å¾
    temporal_features: Optional[torch.Tensor] = None  # æ—¶åºç‰¹å¾ï¼ˆç—…ç¨‹å‘å±•ï¼‰


class MedicalImageEncoder(nn.Module):
    """åŒ»å­¦å½±åƒç¼–ç å™¨ - ä½¿ç”¨DenseNetæ¶æ„ï¼ˆé€‚åˆåŒ»å­¦å½±åƒï¼‰"""

    def __init__(self,
                 modality: str = MedicalModalityType.XRAY,
                 pretrained: bool = True):
        super().__init__()

        self.modality = modality

        # DenseNet-121 ä½œä¸ºåŸºç¡€ç½‘ç»œï¼ˆåŒ»å­¦å½±åƒå¸¸ç”¨ï¼‰
        # ç®€åŒ–ç‰ˆDenseNetå—
        self.initial_conv = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        )

        # Denseå—ï¼ˆç®€åŒ–å®ç°ï¼‰
        self.dense_blocks = nn.Sequential(
            self._make_dense_block(64, 128, 6),
            nn.AvgPool2d(2, 2),
            self._make_dense_block(128, 256, 12),
            nn.AvgPool2d(2, 2),
            self._make_dense_block(256, 512, 24),
            nn.AvgPool2d(2, 2),
            self._make_dense_block(512, 1024, 16)
        )

        # å…¨å±€æ± åŒ–
        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))

        # æ¨¡æ€ç‰¹å®šçš„æŠ•å½±å±‚
        self.modality_projector = self._get_modality_projector(modality)

        self.output_dim = 512

    def _make_dense_block(self, in_channels: int, out_channels: int, num_layers: int):
        """åˆ›å»ºDenseå—ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        layers = []
        for i in range(num_layers):
            layers.append(nn.Sequential(
                nn.BatchNorm2d(in_channels),
                nn.ReLU(inplace=True),
                nn.Conv2d(in_channels, 32, kernel_size=1, stride=1, padding=0),
                nn.BatchNorm2d(32),
                nn.ReLU(inplace=True),
                nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)
            ))
            in_channels = 32

        return nn.Sequential(
            *layers,
            nn.Conv2d(32, out_channels, kernel_size=1)
        )

    def _get_modality_projector(self, modality: str) -> nn.Module:
        """è·å–æ¨¡æ€ç‰¹å®šçš„æŠ•å½±å™¨"""
        if modality == MedicalModalityType.XRAY:
            # Xå…‰ç‰¹å¾å¢å¼º
            return nn.Sequential(
                nn.Linear(1024, 768),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(768, 512)
            )
        elif modality == MedicalModalityType.CT:
            # CTç‰¹å¾å¢å¼ºï¼ˆ3Dä¿¡æ¯ï¼‰
            return nn.Sequential(
                nn.Linear(1024, 896),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(896, 512)
            )
        elif modality == MedicalModalityType.MRI:
            # MRIç‰¹å¾å¢å¼ºï¼ˆå¤šåºåˆ—ï¼‰
            return nn.Sequential(
                nn.Linear(1024, 896),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(896, 512)
            )
        else:
            # é»˜è®¤æŠ•å½±
            return nn.Sequential(
                nn.Linear(1024, 512),
                nn.ReLU()
            )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­

        Args:
            x: [B, C, H, W] åŒ»å­¦å½±åƒ
        """
        # åˆå§‹å·ç§¯
        x = self.initial_conv(x)

        # Denseå—å¤„ç†
        x = self.dense_blocks(x)

        # å…¨å±€æ± åŒ–
        x = self.global_pool(x)
        x = x.flatten(1)

        # æ¨¡æ€ç‰¹å®šæŠ•å½±
        x = self.modality_projector(x)

        return x


class ClinicalDataEncoder(nn.Module):
    """ä¸´åºŠæ•°æ®ç¼–ç å™¨ï¼ˆå®éªŒå®¤æ£€æŸ¥ã€ç”Ÿå‘½ä½“å¾ç­‰ï¼‰"""

    def __init__(self,
                 input_dim: int = 50,  # ä¸´åºŠç‰¹å¾æ•°é‡
                 hidden_dim: int = 256):
        super().__init__()

        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.BatchNorm1d(hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim * 2, hidden_dim)
        )

        # æ—¶åºå»ºæ¨¡ï¼ˆç”¨äºç—…ç¨‹è®°å½•ï¼‰
        self.temporal_encoder = nn.GRU(
            input_size=hidden_dim,
            hidden_size=hidden_dim // 2,
            num_layers=2,
            batch_first=True,
            dropout=0.2
        )

        self.output_dim = hidden_dim

    def forward(self, x: torch.Tensor, use_temporal: bool = False) -> torch.Tensor:
        """
        å¤„ç†ä¸´åºŠæ•°æ®

        Args:
            x: [B, D] æˆ– [B, T, D] ä¸´åºŠç‰¹å¾
            use_temporal: æ˜¯å¦ä½¿ç”¨æ—¶åºç¼–ç 
        """
        if x.dim() == 3 and use_temporal:
            # æ—¶åºæ•°æ®
            B, T, D = x.shape
            x_flat = x.reshape(B * T, D)
            features = self.encoder(x_flat)
            features = features.reshape(B, T, -1)

            # GRUç¼–ç 
            gru_out, _ = self.temporal_encoder(features)
            return gru_out[:, -1, :]
        else:
            # é™æ€æ•°æ®
            if x.dim() == 3:
                x = x.mean(dim=1)
            return self.encoder(x)


class DiseaseSeverityEstimator(nn.Module):
    """ç–¾ç—…ä¸¥é‡ç¨‹åº¦è¯„ä¼°å™¨"""

    def __init__(self, input_dim: int = 512, num_severity_levels: int = 5):
        super().__init__()

        self.estimator = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_severity_levels)
        )

        # ä¸ç¡®å®šæ€§ä¼°è®¡å¤´
        self.uncertainty_head = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è¯„ä¼°ç–¾ç—…ä¸¥é‡ç¨‹åº¦å’Œä¸ç¡®å®šæ€§

        Returns:
            severity_logits: ä¸¥é‡ç¨‹åº¦åˆ†ç±»
            uncertainty: è¯Šæ–­ä¸ç¡®å®šæ€§ [0,1]
        """
        severity_logits = self.estimator(features)
        uncertainty = self.uncertainty_head(features)
        return severity_logits, uncertainty


class MedicalAdapter(nn.Module):
    """
    Medicalé¢†åŸŸé€‚é…å™¨
    ä¸“é—¨å¤„ç†åŒ»ç–—æ•°æ®ï¼Œæ”¯æŒåŒ»å­¦å½±åƒåˆ†æã€ç–¾ç—…è¯Šæ–­ç­‰ä»»åŠ¡
    """

    def __init__(self,
                 modality: str = MedicalModalityType.XRAY,
                 num_diseases: int = 14,  # ChestX-ray14é»˜è®¤14ç§ç–¾ç—…
                 use_clinical_data: bool = False,
                 clinical_dim: int = 50,
                 image_size: int = 224,
                 hidden_dim: int = 512,
                 output_dim: int = 128,  # UniMatchç»Ÿä¸€åµŒå…¥ç»´åº¦
                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
                 **kwargs):

        super().__init__()

        self.modality = modality
        self.num_diseases = num_diseases
        self.use_clinical_data = use_clinical_data
        self.image_size = image_size
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.device = device

        # åŒ»å­¦å½±åƒç¼–ç å™¨
        self.image_encoder = MedicalImageEncoder(
            modality=modality,
            pretrained=True
        )

        # ä¸´åºŠæ•°æ®ç¼–ç å™¨ï¼ˆå¯é€‰ï¼‰
        self.clinical_encoder = None
        if use_clinical_data:
            self.clinical_encoder = ClinicalDataEncoder(
                input_dim=clinical_dim,
                hidden_dim=256
            )

        # å¤šæ¨¡æ€èåˆå±‚
        fusion_input_dim = self.image_encoder.output_dim
        if use_clinical_data:
            fusion_input_dim += self.clinical_encoder.output_dim

        self.fusion_layer = nn.Sequential(
            nn.Linear(fusion_input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

        # ç–¾ç—…åˆ†ç±»å¤´
        self.disease_classifier = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim // 2, num_diseases)
        )

        # ä¸¥é‡ç¨‹åº¦è¯„ä¼°å™¨
        self.severity_estimator = DiseaseSeverityEstimator(
            input_dim=hidden_dim,
            num_severity_levels=5
        )

        # åµŒå…¥æŠ•å½±å™¨ï¼ˆç»Ÿä¸€åˆ°128ç»´ï¼‰
        self.embedding_projector = nn.Sequential(
            nn.Linear(hidden_dim, output_dim * 2),
            nn.BatchNorm1d(output_dim * 2),
            nn.ReLU(),
            nn.Linear(output_dim * 2, output_dim)
        )

        # å›¾åƒé¢„å¤„ç†
        self.image_transform = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],  # ImageNetæ ‡å‡†åŒ–
                std=[0.229, 0.224, 0.225]
            )
        ])

        self.logger = logging.getLogger("MedicalAdapter")

        # ç§»åŠ¨åˆ°è®¾å¤‡
        self.to(device)

    def preprocess_image(self, image: Any) -> torch.Tensor:
        """é¢„å¤„ç†åŒ»å­¦å½±åƒï¼šfloat32 + å½’ä¸€åŒ– + resize + device å¯¹é½"""
        mean = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32, device=self.device).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32, device=self.device).view(1, 3, 1, 1)

        # 1) è½¬æˆ tensorï¼ˆå¦‚éœ€ï¼‰
        if isinstance(image, np.ndarray):
            # [H, W] æˆ– [H, W, C]
            if image.ndim == 2:  # ç°åº¦
                image = np.stack([image] * 3, axis=-1)
            elif image.ndim == 3 and image.shape[-1] == 1:
                image = np.repeat(image, 3, axis=-1)
            image = torch.from_numpy(image).float()  # [H, W, C] or [H, W]

        if not isinstance(image, torch.Tensor):
            raise ValueError(f"Unsupported image type: {type(image)}")

        # 2) ç»´åº¦å¤„ç†åˆ° [B, C, H, W]
        if image.dim() == 2:
            image = image.unsqueeze(0).unsqueeze(0)  # [1,1,H,W]
        elif image.dim() == 3:
            # [C,H,W] or [H,W,C]
            if image.shape[0] in (1, 3):  # [C,H,W]
                image = image.unsqueeze(0)
            else:  # [H,W,C]
                image = image.permute(2, 0, 1).unsqueeze(0)

        # 3) ç°åº¦â†’RGB
        if image.size(1) == 1:
            image = image.repeat(1, 3, 1, 1)  # [B,3,H,W]

        # 4) å½’ä¸€åŒ–åˆ° [0,1]
        if image.max() > 1.0:
            image = image / 255.0

        # 5) resize åˆ°ç›®æ ‡å°ºå¯¸
        if image.shape[-2:] != (self.image_size, self.image_size):
            image = F.interpolate(image, size=(self.image_size, self.image_size), mode='bilinear', align_corners=False)

        # 6) æ ‡å‡†åŒ–
        image = (image.to(self.device, dtype=torch.float32) - mean) / std
        return image

    def extract_features(self, inputs: AdapterInput) -> torch.Tensor:
        """æå–åŒ»ç–—ç‰¹å¾ï¼šå½±åƒ +ï¼ˆå¯é€‰ï¼‰ä¸´åºŠ â†’ èåˆ â†’ è¡¨å¾"""
        # å½±åƒæ•°æ®
        image_data = inputs.raw_data if hasattr(inputs, 'raw_data') else inputs
        image_tensor = self.preprocess_image(image_data)  # [B,3,H,W], float32, device ok

        # å½±åƒç‰¹å¾
        with torch.set_grad_enabled(self.training):
            image_features = self.image_encoder(image_tensor)  # [B, 512]ï¼ˆç”± encoder å®šä¹‰ï¼‰

        # ä¸´åºŠæ•°æ®ï¼ˆå¯é€‰ï¼‰
        if self.use_clinical_data and getattr(inputs, "metadata", None) and 'clinical_data' in inputs.metadata:
            clinical_data = inputs.metadata['clinical_data']
            if not isinstance(clinical_data, torch.Tensor):
                clinical_data = torch.tensor(clinical_data, dtype=torch.float32, device=self.device)
            else:
                clinical_data = clinical_data.to(self.device, dtype=torch.float32)

            clinical_features = self.clinical_encoder(clinical_data)  # [B, hidden]
            fused = torch.cat([image_features, clinical_features], dim=-1)
            features = self.fusion_layer(fused)  # [B, hidden_dim]
        else:
            features = self.fusion_layer(image_features)  # [B, hidden_dim]

        return features

    def compute_confidence(self, embeddings: torch.Tensor,
                           logits: Optional[torch.Tensor] = None) -> torch.Tensor:
        """è®¡ç®—åŒ»ç–—è¯Šæ–­ç½®ä¿¡åº¦"""

        # åŸºç¡€ç½®ä¿¡åº¦ï¼ˆåŸºäºåµŒå…¥èŒƒæ•°ï¼‰
        embedding_norm = torch.norm(embeddings, dim=-1)
        base_confidence = torch.sigmoid(embedding_norm - embedding_norm.mean())

        # å¦‚æœæœ‰åˆ†ç±»logits
        if logits is not None:
            # ç–¾ç—…æ¦‚ç‡åˆ†å¸ƒ
            disease_probs = torch.sigmoid(logits)  # å¤šæ ‡ç­¾åˆ†ç±»ç”¨sigmoid

            # æœ€å¤§æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦çš„ä¸€éƒ¨åˆ†
            max_prob = disease_probs.max(dim=-1)[0]

            # ç†µä½œä¸ºä¸ç¡®å®šæ€§åº¦é‡
            entropy = -torch.sum(disease_probs * torch.log(disease_probs + 1e-8), dim=-1)
            entropy_confidence = 1.0 - (entropy / np.log(logits.size(-1)))

            # ç»„åˆç½®ä¿¡åº¦
            confidence = base_confidence * 0.3 + max_prob * 0.4 + entropy_confidence * 0.3
        else:
            confidence = base_confidence

        return torch.clamp(confidence, 0.0, 1.0)

    def detect_rare_disease(self, features: torch.Tensor) -> Dict[str, Any]:
        """æ£€æµ‹ç½•è§ç–¾ç—…"""

        with torch.no_grad():
            # è·å–ç–¾ç—…é¢„æµ‹
            disease_logits = self.disease_classifier(features)
            disease_probs = torch.sigmoid(disease_logits)

            # ä¸¥é‡ç¨‹åº¦å’Œä¸ç¡®å®šæ€§
            severity_logits, uncertainty = self.severity_estimator(features)
            severity_probs = F.softmax(severity_logits, dim=-1)

            # ç½•è§ç–¾ç—…æ£€æµ‹é€»è¾‘
            # 1. ä½æ¦‚ç‡ä½†é«˜ä¸¥é‡ç¨‹åº¦
            # 2. é«˜ä¸ç¡®å®šæ€§
            rare_disease_score = (1 - disease_probs.max(dim=-1)[0]) * \
                                 severity_probs[:, -1] * uncertainty.squeeze()

            # é˜ˆå€¼åˆ¤æ–­
            is_rare = rare_disease_score > 0.5

        return {
            'is_rare_disease': is_rare.cpu().numpy(),
            'rare_disease_score': rare_disease_score.cpu().numpy(),
            'disease_probs': disease_probs.cpu().numpy(),
            'severity': severity_probs.argmax(dim=-1).cpu().numpy(),
            'uncertainty': uncertainty.cpu().numpy()
        }

    def forward(self, inputs: AdapterInput) -> AdapterOutput:
        """å‰å‘ä¼ æ’­ï¼šç‰¹å¾â†’åˆ†ç±»â†’æŠ•å½±â†’ç½®ä¿¡åº¦â†’å›°éš¾æ ·æœ¬/å…ƒæ•°æ®"""
        # ä¿é™©ï¼šæŠŠå¼ é‡è¾“å…¥è¿åˆ°æ­£ç¡®è®¾å¤‡ + dtype
        if isinstance(inputs.raw_data, torch.Tensor):
            inputs.raw_data = inputs.raw_data.to(self.device, dtype=torch.float32)

        # æå–ç‰¹å¾
        features = self.extract_features(inputs)  # [B, hidden_dim]

        # ç–¾ç—…åˆ†ç±»ï¼ˆå¤šæ ‡ç­¾ï¼‰
        disease_logits = self.disease_classifier(features)  # [B, num_diseases]

        # ç»Ÿä¸€åµŒå…¥ç©ºé—´
        embeddings = self.embedding_projector(features)  # [B, output_dim]

        # ç½®ä¿¡åº¦
        confidence = self.compute_confidence(embeddings, disease_logits)  # [B]

        # å›°éš¾æ ·æœ¬ï¼ˆåŒ»ç–—é»˜è®¤é˜ˆå€¼ 0.75ï¼‰
        is_hard = confidence < 0.75

        # ä¸¥é‡ç¨‹åº¦ & ä¸ç¡®å®šæ€§
        severity_logits, uncertainty = self.severity_estimator(features)

        outputs = AdapterOutput(
            embeddings=embeddings,
            logits=disease_logits,
            confidence_scores=confidence,
            is_hard_sample=is_hard,
            metadata={
                'modality': self.modality,
                'num_diseases': self.num_diseases,
                'severity_logits': severity_logits.detach().cpu(),
                'diagnostic_uncertainty': uncertainty.detach().cpu(),
                'domain': 'medical'
            }
        )

        # å¯é€‰ï¼šç½•è§ç—…æ£€æµ‹
        if getattr(inputs, "metadata", None) and inputs.metadata.get('detect_rare', False):
            rare_result = self.detect_rare_disease(features)
            outputs.metadata.update(rare_result)

        return outputs

    def get_embedding_dim(self) -> int:
        """è·å–åµŒå…¥ç»´åº¦"""
        return self.output_dim

    def set_mode(self, mode: str):
        """è®¾ç½®é€‚é…å™¨æ¨¡å¼"""
        if mode == AdapterMode.TRAINING:
            self.train()
        else:
            self.eval()


# =====================================================
# æµ‹è¯•å‡½æ•°
# =====================================================

def test_medical_adapter():
    """æµ‹è¯•Medicalé€‚é…å™¨"""

    print("ğŸ¥ æµ‹è¯•Medicalé€‚é…å™¨...")

    # åˆ›å»ºé€‚é…å™¨
    adapter = MedicalAdapter(
        modality=MedicalModalityType.XRAY,
        num_diseases=14,  # ChestX-ray14
        use_clinical_data=True,
        clinical_dim=50,
        image_size=224,
        hidden_dim=512,
        output_dim=128  # UniMatchç»Ÿä¸€ç»´åº¦
    )

    print(f"âœ… åˆ›å»ºMedicalé€‚é…å™¨")
    print(f"ğŸ“ è¾“å‡ºç»´åº¦: {adapter.get_embedding_dim()}")
    print(f"ğŸ¥ æ¨¡æ€: {adapter.modality}")
    print(f"ğŸ’Š ç–¾ç—…æ•°: {adapter.num_diseases}")

    # æ¨¡æ‹Ÿæ•°æ®
    batch_size = 4

    # æ¨¡æ‹ŸXå…‰å›¾åƒ (ç°åº¦å›¾)
    test_images = torch.randn(batch_size, 1, 224, 224)

    # æ¨¡æ‹Ÿä¸´åºŠæ•°æ®
    clinical_data = torch.randn(batch_size, 50)

    # åˆ›å»ºè¾“å…¥
    inputs = AdapterInput(
        raw_data=test_images,
        labels=torch.randint(0, 2, (batch_size, 14)).float(),  # å¤šæ ‡ç­¾
        metadata={
            'clinical_data': clinical_data,
            'detect_rare': True,
            'source': 'chestx_ray14'
        }
    )

    # è®¾ç½®è¯„ä¼°æ¨¡å¼
    adapter.set_mode(AdapterMode.INFERENCE)

    # å¤„ç†
    outputs = adapter(inputs)

    print(f"\nğŸ“ˆ å¤„ç†ç»“æœ:")
    print(f"åµŒå…¥å½¢çŠ¶: {outputs.embeddings.shape}")
    print(f"ç–¾ç—…é¢„æµ‹å½¢çŠ¶: {outputs.logits.shape}")
    print(f"ç½®ä¿¡åº¦: {outputs.confidence_scores.detach().cpu().numpy()}")
    print(f"å›°éš¾æ ·æœ¬: {outputs.is_hard_sample.cpu().numpy()}")
    print(f"è¯Šæ–­ä¸ç¡®å®šæ€§: {outputs.metadata['diagnostic_uncertainty'].numpy().flatten()}")

    # ç½•è§ç–¾ç—…æ£€æµ‹ç»“æœ
    if 'is_rare_disease' in outputs.metadata:
        print(f"\nğŸ¯ ç½•è§ç–¾ç—…æ£€æµ‹:")
        print(f"ç½•è§ç—…åˆ†æ•°: {outputs.metadata['rare_disease_score']}")
        print(f"æ£€æµ‹ç»“æœ: {outputs.metadata['is_rare_disease']}")
        print(f"ä¸¥é‡ç¨‹åº¦: {outputs.metadata['severity']}")

    # æµ‹è¯•ä¸åŒæ¨¡æ€
    print(f"\nğŸ”„ æµ‹è¯•å…¶ä»–æ¨¡æ€...")

    for modality in [MedicalModalityType.CT, MedicalModalityType.MRI]:
        adapter_modal = MedicalAdapter(
            modality=modality,
            num_diseases=10,
            output_dim=128
        )

        test_input = AdapterInput(
            raw_data=torch.randn(2, 3, 224, 224),
            labels=torch.randint(0, 2, (2, 10)).float()
        )

        adapter_modal.eval()
        outputs_modal = adapter_modal(test_input)
        print(f"âœ… {modality} æ¨¡æ€: åµŒå…¥å½¢çŠ¶ {outputs_modal.embeddings.shape}")

    print("\nâœ… Medicalé€‚é…å™¨æµ‹è¯•å®Œæˆï¼")
    print("ğŸ“Š å…³é”®æŒ‡æ ‡éªŒè¯:")
    print(f"  - è¾“å‡ºç»´åº¦: 128 âœ“")
    print(f"  - ç½®ä¿¡åº¦èŒƒå›´: [0, 1] âœ“")
    print(f"  - å›°éš¾æ ·æœ¬è¯†åˆ«: åŠŸèƒ½æ­£å¸¸ âœ“")
    print(f"  - ç½•è§ç–¾ç—…æ£€æµ‹: åŠŸèƒ½æ­£å¸¸ âœ“")
    print(f"  - å¤šæ¨¡æ€æ”¯æŒ: X-ray/CT/MRI âœ“")

    return True


if __name__ == "__main__":
    test_success = test_medical_adapter()
    if test_success:
        print("\nğŸ‰ Medicalé€‚é…å™¨å°±ç»ªï¼å¯ä»¥è¿›è¡Œå››åŸŸé›†æˆæµ‹è¯•ã€‚")